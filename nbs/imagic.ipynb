{
 "cells": [
  {
   "cell_type": "raw",
   "id": "42287698-67d5-46fe-befc-d17c15a06bbd",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"imagic\"\n",
    "toc: true\n",
    "toc-expand: 2\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422d3e30-e152-4e06-9b62-29aec2cfafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages (0.38.1)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "!pip install diffusers\n",
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install nbdev\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87fff5a1-99ae-49f7-9a6a-383cfd460e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "CUDA SETUP: Loading binary /Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n",
      "dlopen(/Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so, 0x0006): tried: '/Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so' (not a mach-o file), '/System/Volumes/Preboot/Cryptexes/OS/Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so' (no such file), '/Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so' (not a mach-o file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/bitsandbytes/cextension.py:33: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import AutoencoderKL,UNet2DConditionModel,LMSDiscreteScheduler,DDPMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import torch,numpy as np\n",
    "import torch.nn.functional as F,torch.nn as nn\n",
    "from torchvision import transforms as tfms\n",
    "from  PIL import Image\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import dataset, sampler, dataloader\n",
    "import gc,os\n",
    "import bitsandbytes as bnb\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85291342-1940-4a51-901e-64c7cdf986cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp imageic_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066807e-10c6-4c4b-ab87-397d24c89eca",
   "metadata": {},
   "source": [
    "## 超参准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58037b82-af30-4039-9bb3-ab97afdc6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class HiperParam:\n",
    "    prompt:str='A photo of Barack Obama smiling with a big grin.'\n",
    "    #训练步数\n",
    "    optimizer_training_loop:int=4\n",
    "    unet_training_loop:int=3\n",
    "    mix_precison:str='no'\n",
    "    min_timestamps:int=0\n",
    "    max_timestamps:int=1000\n",
    "    use_8bit_adam:bool=False\n",
    "\n",
    "    lr:float=1e-6\n",
    "    lr_emb:float=1e-3\n",
    "    \n",
    "    batch_size:int=1    \n",
    "    accum_steps:int=1\n",
    "    \n",
    " \n",
    "    enable_gradient_checkpointing:bool=True\n",
    "     \n",
    "    \n",
    "    output:str='weights'\n",
    "    log_interval:int=1\n",
    "    eval_interval:int=1000\n",
    "    \n",
    "hparam=HiperParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2535dc74-25f8-498a-a609-fb1de96c355f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HiperParam(prompt='A photo of Barack Obama smiling with a big grin.', optimizer_training_loop=4, unet_training_loop=3, mix_precison='no', min_timestamps=0, max_timestamps=1000, use_8bit_adam=False, lr=1e-06, lr_emb=0.001, batch_size=1, accum_steps=1, enable_gradient_checkpointing=True, output='weights', log_interval=1, eval_interval=1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    hparam.output='/content/drive/MyDrive/'+hparam.output\n",
    "except:\n",
    "    pass\n",
    "os.makedirs(hparam.output,exist_ok=True)\n",
    "hparam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e6817-4cf1-40c5-86b2-7dc301e9291d",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5bf41d-1c95-4b13-a5b8-4413365aab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前环境不是Colab\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def release_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    \n",
    "#把图片排成 rows,cols的网格中，先排cols,后排rows\n",
    "#其中len(imgs)=cols x rows\n",
    "def image_grid(imgs, rows, cols):\n",
    "    w,h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "def isColab(versoze=False):\n",
    "    try:\n",
    "        import google.colab\n",
    "        IN_COLAB = True\n",
    "    except:\n",
    "        IN_COLAB = False\n",
    "    if versoze:\n",
    "        if IN_COLAB:\n",
    "            print(\"当前环境是Colab\")\n",
    "        else:\n",
    "            print(\"当前环境不是Colab\")\n",
    "    return IN_COLAB\n",
    "_=isColab(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e55b5-220d-4da3-b959-6cae280e9c8e",
   "metadata": {},
   "source": [
    "## 模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e513a44d-a343-4c50-97b1-ee3a8fad60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "modelName=\"CompVis/stable-diffusion-v1-4\"\n",
    "vae,tokenizer,text_encoder,unet,schedular=None,None,None,None,None\n",
    "def prepare_model():\n",
    "    global vae,tokenizer,text_encoder,unet,schedular\n",
    "    if unet is not None:return\n",
    "    vae=AutoencoderKL.from_pretrained(modelName,subfolder='vae')\n",
    "    tokenizer=CLIPTokenizer.from_pretrained(modelName,subfolder=\"tokenizer\")\n",
    "    text_encoder=CLIPTextModel.from_pretrained(modelName,subfolder=\"text_encoder\")\n",
    "    unet=UNet2DConditionModel.from_pretrained(modelName,subfolder='unet')\n",
    "    schedular=DDPMScheduler(beta_schedule='scaled_linear',beta_start=0.00085, beta_end=0.012 )\n",
    "\n",
    "    release_cache()\n",
    "@torch.no_grad()\n",
    "def pil2Latents(input_image:Image)-> torch.FloatTensor:\n",
    "    '''\n",
    "    把图片转换成vae的输入，生成的tensor在cpu上\n",
    "    对图片进行的缩放处理，短边变成512px，长边采用中心切割的方式。\n",
    "    返回：size=[1,4,64,64]\n",
    "    '''\n",
    "    image_transforms = tfms.Compose(\n",
    "        [\n",
    "            tfms.Resize(512, interpolation=tfms.InterpolationMode.BILINEAR),\n",
    "            tfms.CenterCrop(512),\n",
    "            tfms.ToTensor(),\n",
    "            tfms.Normalize([0.5], [0.5]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ts=image_transforms(input_image).unsqueeze(0).to(vae.device,vae.dtype)\n",
    "    return 0.18215*vae.encode(ts).latent_dist.sample()\n",
    "@torch.no_grad()\n",
    "def latents2Pil(latents:torch.FloatTensor) ->Image:\n",
    "    '''\n",
    "    把隐变量还原成PIL.Image\n",
    "    latents: FloatTensor,size=[1,4,64,64]\n",
    "    '''\n",
    "    # [-1,1] \n",
    "    latent_transforms=tfms.Normalize([-1], [2])\n",
    "    \n",
    "    decode_img=vae.decode(latents/0.18215).sample.detach().cpu()\n",
    "    decode_img=decode_img.permute(0,2,3,1).squeeze()\n",
    "    decode_img=latent_transforms(decode_img).float().clamp(0,1)\n",
    "\n",
    "    arr_img=decode_img.numpy()*255\n",
    "    arr_img=arr_img.astype('uint8')\n",
    "    return Image.fromarray(arr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4b5a3b9-65ec-44ad-a5a8-3b0a5af02d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_model()\n",
    "# img=Image.open('imgs/Obama.jpg')\n",
    "# lt=pil2Latents(img)\n",
    "# latents2Pil(lt).resize((64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2437e-256a-4410-8066-815b10886ae2",
   "metadata": {},
   "source": [
    "## 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b5879c-b3a5-401a-bd3f-0a671ff43423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImageDataSet(dataset.Dataset):\n",
    "    def __init__(self,path) :\n",
    "        self.data=pil2Latents(Image.open(path))\n",
    "        self.ids=tokenizer(hparam.prompt,padding='max_length',truncation=True,max_length=tokenizer.model_max_length,return_tensors='pt').input_ids\n",
    "    def __len__(self):\n",
    "        return hparam.batch_size\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        noise=torch.randn_like(self.data) #这里需要to\n",
    "        ts=torch.randint(hparam.min_timestamps,hparam.max_timestamps,(hparam.batch_size,)) #这里需要to\n",
    "        model_inp1=schedular.add_noise(self.data,noise,ts)\n",
    "\n",
    "        return model_inp1[0],ts[0],self.ids[0],noise[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a3550-e50e-429f-92fb-0037f0bccd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir imgs\n",
    "!wget -O imgs/Obama.jpg \"https://github.com/ShivamShrirao/diffusers/blob/main/examples/imagic/imgs/Official_portrait_of_Barack_Obama.jpg?raw=true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae520df5-5e16-4e93-8b68-ea4471b17c27",
   "metadata": {},
   "source": [
    "## 训练代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62761725-e806-4d2c-b51d-defa9aefced7",
   "metadata": {},
   "source": [
    "训练主流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d09c61a2-8c27-41ba-b421-847e16c071b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getUNetParams(unet):\n",
    "    if isColab():\n",
    "        return unet.parameters()\n",
    "    else:\n",
    "        return unet.conv_out.parameters() \n",
    "\n",
    "def freeze_weight(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(False)\n",
    "def unFreeze_weight(model):\n",
    "    params=model.parameters()\n",
    "    if isinstance(model,UNet2DConditionModel):\n",
    "        params=getUNetParams(model)\n",
    "    for p in params:\n",
    "        p.requires_grad_(True)\n",
    "        \n",
    "def train_func(hparam,text_encoder,unet):\n",
    "    ds=ImageDataSet('imgs/Obama.jpg')\n",
    "    dls=dataloader.DataLoader(ds,hparam.batch_size,shuffle=False)\n",
    "\n",
    "    accelertor=Accelerator(\n",
    "        mixed_precision=hparam.mix_precison,\n",
    "        gradient_accumulation_steps=hparam.accum_steps)\n",
    "    #默认全部都不参与训练\n",
    "    freeze_weight(unet)\n",
    "    if hparam.enable_gradient_checkpointing:\n",
    "        unet.enable_gradient_checkpointing()\n",
    "    \n",
    "    dls,unet,text_encoder=accelertor.prepare(dls,unet,text_encoder)\n",
    "    \n",
    "    \n",
    "    def save_model(obj,name):\n",
    "        if accelertor.is_main_process:\n",
    "            torch.save(obj,f'{hparam.output}/{name}.pt')\n",
    "            \n",
    "    _,_,ids,_ =next(iter(dls))\n",
    "    with torch.inference_mode():\n",
    "        target_emb=text_encoder(ids).last_hidden_state\n",
    "        save_model(target_emb,'target')\n",
    "    optimized_emb=nn.Parameter(target_emb.clone())\n",
    "    del text_encoder\n",
    "    release_cache()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_one_stage(pbar,optimizer,t_inp,bar_prmpt):\n",
    "        pbar.set_description(bar_prmpt)\n",
    "        for i in pbar:\n",
    "            for model_inp1,t,ids,noise in dls:\n",
    "                with accelertor.accumulate(unet):\n",
    "                    noise_pred = unet(model_inp1, t, encoder_hidden_states=t_inp).sample\n",
    "                    # loss=F.mse_loss(noise_pred,noise)\n",
    "                    loss=F.mse_loss(noise_pred.float(),noise.float())\n",
    "                    accelertor.backward(loss)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    if i%hparam.log_interval==0:\n",
    "                        pbar.set_postfix(Loss=f\"{loss.cpu().item():.3f}\")\n",
    "    \n",
    "    optimize_class=bnb.optim.Adam8bit if hparam.use_8bit_adam else torch.optim.Adam\n",
    "    #第一阶段的训练,token_embedding.weights\n",
    "    \n",
    "    optimizer=accelertor.prepare(optimize_class([optimized_emb],hparam.lr_emb))\n",
    "    pbar=tqdm(range(hparam.optimizer_training_loop),disable=not accelertor.is_main_process)\n",
    "    \n",
    "    train_one_stage(pbar,optimizer,optimized_emb,\"step 1\")\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        save_model(optimized_emb,'optimizer')\n",
    "    \n",
    "    optimized_emb.requires_grad_(False)\n",
    "    \n",
    "    \n",
    "    release_cache()\n",
    "    #第二阶段的训练,unet.weights\n",
    "    \n",
    "    \n",
    "    unFreeze_weight(unet)\n",
    "    \n",
    "    unet.train()\n",
    "    pbar=tqdm(range(hparam.unet_training_loop),disable=not accelertor.is_main_process)\n",
    "    #accelerator.unwrap_model(unet).parameters(),\n",
    "    optimizer=accelertor.prepare(optimize_class(getUNetParams(accelertor.unwrap_model(unet)),hparam.lr))\n",
    "\n",
    "    train_one_stage(pbar,optimizer,optimized_emb,\"step 2\")\n",
    "    \n",
    "    save_model(accelertor.unwrap_model(unet).state_dict(),'unet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5430889-0354-4242-b79f-6cff6cc364a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on MPS.\n",
      "pynvml module not found, please install pynvml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9dc6f9460004095a7b8ffc24c2c5f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhanggxk/project/anaconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml module not found, please install pynvml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88a99b8787148348f77494e31fb18bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "# from nbdev import nbdev_export\n",
    "# nbdev_export('.')\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     train_func(hparam,dls,text_encoder,unet) \n",
    "# from accelerate import notebook_launcher\n",
    "\n",
    "# notebook_launcher(train_func,(hparam,text_encoder,unet),num_processes=1,mixed_precision='fp16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb982675-8662-4104-89c5-7061498f0257",
   "metadata": {},
   "source": [
    "## 推理代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "908eaf1f-6c8c-49af-b814-3213d9d4ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline,DDPMScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e75038-7977-4dd5-b6f6-79650d34f58b",
   "metadata": {},
   "source": [
    "1.重新加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7f37e7d-f44b-41ea-8aa2-08cf40b17b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch_type=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "target_emb,optimemb=None,None\n",
    "prepare_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63719b3a-2f44-41d5-8e73-387573dfcee0",
   "metadata": {},
   "source": [
    "2.加载训练好的unet,target_emb,optimemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c22e0c-c07a-48c2-8f2a-bb6528d5c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights():\n",
    "    global target_emb,optimemb,unet\n",
    "    target_emb=torch.load(f'{hparam.output}/target.pt',map_location='cpu')\n",
    "    optimemb=torch.load(f'{hparam.output}/optimizer.pt',map_location='cpu')\n",
    "    unet_state=torch.load(f'{hparam.output}/unet.pt',map_location='cpu')\n",
    "    unet.load_state_dict(unet_state)\n",
    "pipe=StableDiffusionPipeline(vae,text_encoder,tokenizer,unet,schedular,None,None).to(torch_device,torch_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fba815e9-073f-4554-82d6-8e25244e202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420ed7c-f4b5-4333-8493-5eab6353f2fa",
   "metadata": {},
   "source": [
    "以下2行代码去检测训练出来的参数到底有没有意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106acf9-cd85-4ec7-ab73-588ae424f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_valid_result(prompt='dog',flag=''):\n",
    "    \n",
    "    if flag=='target':   \n",
    "        return pipe(prompt_embeds=target_emb).images[0]\n",
    "    elif flag=='optimized':    \n",
    "        return pipe(prompt_embeds=optimemb).images[0]\n",
    "    else:\n",
    "        return pipe(prompt).images[0]\n",
    "test_valid_result(flag='target')\n",
    "# test_valid_result(flag='optimized')\n",
    "# test_valid_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e1b6c-9abd-484a-8efb-bbe932342633",
   "metadata": {},
   "source": [
    "pipe调用参数[参考文档](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b017a6b7-ee5b-477c-a987-454c9feddb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_latent=pil2Latents(Image.open('Obama.jpg'))\n",
    "# img_latent=schedular.add_noise(img_latent,torch.rand_like(img_latent),torch.tensor([999]))\n",
    "\n",
    "# g_cuda = torch.Generator(device=torch_device)\n",
    "# seed = 4324 #@param {type:\"number\"}\n",
    "# g_cuda.manual_seed(seed)\n",
    "                   \n",
    "# with torch.inference_mode():\n",
    "#     images = pipe(\n",
    "#         prompt_embeds=token_emb,\n",
    "#         num_images_per_prompt=1,\n",
    "#         num_inference_steps=10,\n",
    "#         guidance_scale=7.5,\n",
    "#         generator=g_cuda,\n",
    "#         latents=img_latent\n",
    "#     ).images\n",
    "# image_grid(images,1,len(images)).resize((256*len(images),256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bb582-ef48-4407-af00-73afe572eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_grid(images,1,len(images)).resize((256*len(images),256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5529e-e2b0-4c9f-b5c2-ea1388931185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
