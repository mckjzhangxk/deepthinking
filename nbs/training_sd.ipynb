{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d3e30-e152-4e06-9b62-29aec2cfafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "!pip install diffusers\n",
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install nbdev\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87fff5a1-99ae-49f7-9a6a-383cfd460e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import AutoencoderKL,UNet2DConditionModel,LMSDiscreteScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import torch,numpy as np\n",
    "import torch.nn.functional as F,torch.nn as nn\n",
    "from torchvision import transforms as tfms\n",
    "from  PIL import Image\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import dataset, sampler, dataloader\n",
    "import gc,os\n",
    "import bitsandbytes as bnb\n",
    "from accelerate import Accelerator\n",
    "    # from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85291342-1940-4a51-901e-64c7cdf986cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp imageic_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066807e-10c6-4c4b-ab87-397d24c89eca",
   "metadata": {},
   "source": [
    "## 超参准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58037b82-af30-4039-9bb3-ab97afdc6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class HiperParam:\n",
    "    optimizer_training_loop:int=4\n",
    "    unet_training_loop:int=3\n",
    "    batch_size:int=1\n",
    "    lr:float=1e-6\n",
    "    lr_emb:float=1e-3\n",
    "    accum_steps:int=1\n",
    "    mix_precison:str='no'\n",
    "    enable_gradient_checkpointing:bool=True\n",
    "    prompt:str='A photo of Barack Obama smiling with a big grin.'\n",
    "    \n",
    "    output:str='weights'\n",
    "    log_interval:int=1\n",
    "hparam=HiperParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6707ec54-7d74-444d-8741-446884861100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HiperParam(optimizer_training_loop=4, unet_training_loop=3, batch_size=1, lr=1e-06, lr_emb=0.001, accum_steps=1, mix_precison='no', enable_gradient_checkpointing=True, prompt='A photo of Barack Obama smiling with a big grin.', output='weights', log_interval=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(hparam.output,exist_ok=True)\n",
    "hparam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e6817-4cf1-40c5-86b2-7dc301e9291d",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5bf41d-1c95-4b13-a5b8-4413365aab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前环境不是Colab\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def release_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    \n",
    "#把图片排成 rows,cols的网格中，先排cols,后排rows\n",
    "#其中len(imgs)=cols x rows\n",
    "def image_grid(imgs, rows, cols):\n",
    "    w,h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "def isColab(versoze=False):\n",
    "    try:\n",
    "        import google.colab\n",
    "        IN_COLAB = True\n",
    "    except:\n",
    "        IN_COLAB = False\n",
    "    if versoze:\n",
    "        if IN_COLAB:\n",
    "            print(\"当前环境是Colab\")\n",
    "        else:\n",
    "            print(\"当前环境不是Colab\")\n",
    "    return IN_COLAB\n",
    "_=isColab(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e55b5-220d-4da3-b959-6cae280e9c8e",
   "metadata": {},
   "source": [
    "## 模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f137405b-aecd-4618-862e-555daba7cf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml module not found, please install pynvml\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "modelName=\"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "vae=AutoencoderKL.from_pretrained(modelName,subfolder='vae')\n",
    "tokenizer=CLIPTokenizer.from_pretrained(modelName,subfolder=\"tokenizer\")\n",
    "text_encoder=CLIPTextModel.from_pretrained(modelName,subfolder=\"text_encoder\")\n",
    "unet=UNet2DConditionModel.from_pretrained(modelName,subfolder='unet')\n",
    "schedular=LMSDiscreteScheduler(beta_schedule='scaled_linear',beta_start=0.00085, beta_end=0.012 )\n",
    "\n",
    "release_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e513a44d-a343-4c50-97b1-ee3a8fad60ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad()\n",
    "def pil2Latents(input_image:Image)-> torch.FloatTensor:\n",
    "    '''\n",
    "    把图片转换成vae的输入，生成的tensor在cpu上\n",
    "    对图片进行的缩放处理，短边变成512px，长边采用中心切割的方式。\n",
    "    返回：size=[1,4,64,64]\n",
    "    '''\n",
    "    image_transforms = tfms.Compose(\n",
    "        [\n",
    "            tfms.Resize(512, interpolation=tfms.InterpolationMode.BILINEAR),\n",
    "            tfms.CenterCrop(512),\n",
    "            tfms.ToTensor(),\n",
    "            tfms.Normalize([0.5], [0.5]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ts=image_transforms(input_image).unsqueeze(0)\n",
    "    return 0.18215*vae.encode(ts).latent_dist.sample()\n",
    "@torch.no_grad()\n",
    "def latents2Pil(latents:torch.FloatTensor) ->Image:\n",
    "    '''\n",
    "    把隐变量还原成PIL.Image\n",
    "    latents: FloatTensor,size=[1,4,64,64]\n",
    "    '''\n",
    "    # [-1,1] \n",
    "    latent_transforms=tfms.Normalize([-1], [2])\n",
    "    \n",
    "    decode_img=vae.decode(latents/0.18215).sample.detach().cpu()\n",
    "    decode_img=decode_img.permute(0,2,3,1).squeeze()\n",
    "    decode_img=latent_transforms(decode_img).float().clamp(0,1)\n",
    "\n",
    "    arr_img=decode_img.numpy()*255\n",
    "    arr_img=arr_img.astype('uint8')\n",
    "    return Image.fromarray(arr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4b5a3b9-65ec-44ad-a5a8-3b0a5af02d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open('Obama.jpg')\n",
    "lt=pil2Latents(img)\n",
    "latents2Pil(lt).resize((64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2437e-256a-4410-8066-815b10886ae2",
   "metadata": {},
   "source": [
    "## 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b5879c-b3a5-401a-bd3f-0a671ff43423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImageDataSet(dataset.Dataset):\n",
    "    def __init__(self,path) :\n",
    "        self.data=pil2Latents(Image.open(path))\n",
    "        self.ids=tokenizer(hparam.prompt,padding='max_length',truncation=True,max_length=tokenizer.model_max_length,return_tensors='pt').input_ids\n",
    "    def __len__(self):\n",
    "        return hparam.batch_size\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        noise=torch.rand_like(self.data) #这里需要to\n",
    "        ts=torch.randint(0,1000,(1,)) #这里需要to\n",
    "        model_inp1=schedular.add_noise(self.data,noise,ts)\n",
    "\n",
    "        return model_inp1[0],ts[0],self.ids[0],noise[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a3550-e50e-429f-92fb-0037f0bccd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O Obama.jpg \"https://github.com/ShivamShrirao/diffusers/blob/main/examples/imagic/imgs/Official_portrait_of_Barack_Obama.jpg?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6552807-c171-42cc-a27e-30a88e88751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 64, 64]) torch.Size([1, 77]) tensor([711]) torch.Size([1, 4, 64, 64])\n",
      "pynvml module not found, please install pynvml\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "ds=ImageDataSet('Obama.jpg')\n",
    "dls=dataloader.DataLoader(ds,hparam.batch_size,shuffle=False)\n",
    "for lt,t,tx,noise in dls:\n",
    "    print(lt.shape,tx.shape,t,noise.shape)\n",
    "del vae \n",
    "release_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae520df5-5e16-4e93-8b68-ea4471b17c27",
   "metadata": {},
   "source": [
    "## 训练代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62761725-e806-4d2c-b51d-defa9aefced7",
   "metadata": {},
   "source": [
    "训练主流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d09c61a2-8c27-41ba-b421-847e16c071b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getUNetParams(unet):\n",
    "    if isColab():\n",
    "        return unet.parameters()\n",
    "    else:\n",
    "        return unet.conv_out.parameters() \n",
    "\n",
    "def freeze_weight(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(False)\n",
    "def unFreeze_weight(model):\n",
    "    params=model.parameters()\n",
    "    if isinstance(model,UNet2DConditionModel):\n",
    "        params=getUNetParams(model)\n",
    "    for p in params:\n",
    "        p.requires_grad_()\n",
    "        \n",
    "\n",
    "def train_func(hparam,dls,text_encoder,unet):\n",
    "    accelertor=Accelerator(\n",
    "        mixed_precision=hparam.mix_precison,\n",
    "        gradient_accumulation_steps=hparam.accum_steps)\n",
    "    #默认全部都不参与训练\n",
    "    freeze_weight(unet)\n",
    "    if hparam.enable_gradient_checkpointing:\n",
    "        unet.enable_gradient_checkpointing()\n",
    "    \n",
    "    dls,unet,text_encoder=accelertor.prepare(dls,unet,text_encoder)\n",
    "    \n",
    "    \n",
    "    def save_model(obj,name):\n",
    "        if accelertor.is_main_process:\n",
    "            torch.save(obj,f'{hparam.output}/{name}.pt')\n",
    "            \n",
    "    _,_,ids,_ =next(iter(dls))\n",
    "    with torch.inference_mode():\n",
    "        target_emb=text_encoder(ids)\n",
    "        save_model(target_emb,'target')\n",
    "    optimized_emb=nn.Parameter(target_emb.last_hidden_state.float().clone())\n",
    "    del text_encoder\n",
    "    release_cache()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_one_stage(pbar,optimizer,t_inp):\n",
    "        for i in pbar:\n",
    "            for model_inp1,t,ids,noise in dls:\n",
    "                with accelertor.accumulate(unet):\n",
    "                    noise_pred = unet(model_inp1, t, encoder_hidden_states=t_inp).sample\n",
    "                    loss=F.mse_loss(noise_pred,noise)\n",
    "                    accelertor.backward(loss)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    if i%hparam.log_interval==0:\n",
    "                        pbar.set_postfix(Loss=f\"{loss.cpu().item():.3f}\")\n",
    "    #第一阶段的训练,token_embedding.weights\n",
    "    \n",
    "    optimizer=accelertor.prepare(torch.optim.Adam([optimized_emb],hparam.lr_emb))\n",
    "    pbar=tqdm(range(hparam.optimizer_training_loop),disable=not accelertor.is_main_process)\n",
    "    pbar.set_description(\"step 1\")\n",
    "    train_one_stage(pbar,optimizer,optimized_emb)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        save_model(optimized_emb,'optimizer')\n",
    "    \n",
    "    optimized_emb.requires_grad_(False)\n",
    "    \n",
    "    \n",
    "    release_cache()\n",
    "    #第二阶段的训练,unet.weights\n",
    "    \n",
    "    \n",
    "    unFreeze_weight(unet)\n",
    "    \n",
    "    \n",
    "    pbar=tqdm(range(hparam.unet_training_loop),disable=not accelertor.is_main_process)\n",
    "    optimizer=accelertor.prepare(torch.optim.Adam(getUNetParams(unet),hparam.lr))\n",
    "\n",
    "    pbar.set_description(\"step 2\")\n",
    "    train_one_stage(pbar,optimizer,optimized_emb)\n",
    "    \n",
    "    save_model(unet.state_dict(),'unet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f858ea9-23d1-4559-b39e-ac3d390cc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml module not found, please install pynvml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e857b53c3074744aaf0ee51fe241096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml module not found, please install pynvml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f93a5ee0db40e9a3c43f649b055e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    train_func(hparam,dls,text_encoder,unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd7bbc3-f855-4e21-a0e6-9434a5254142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import nbdev_export\n",
    "nbdev_export('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5430889-0354-4242-b79f-6cff6cc364a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on MPS.\n",
      "pynvml module not found, please install pynvml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b5017e426a4adf93e188dd776274c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml module not found, please install pynvml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902eaf429e1749d4bbc5bee19bb337a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(train_func,(hparam,dls,text_encoder,unet),num_processes=1,mixed_precision='fp16')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
